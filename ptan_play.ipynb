{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playing Atari using PTAN library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning) \n",
    "# suppress numpy future warnings \n",
    "# warning created due to issues with tensorflow 1.14\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import ptan\n",
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "from lib import dqn_model, common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "seed = 2390857\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = common.HYPERPARAMS['pong']\n",
    "\n",
    "# Get parameters as specified in ./lib/common.py file\n",
    "\n",
    "# HYPERPARAMS = {\n",
    "#     'pong': {\n",
    "#         'env_name':         \"PongNoFrameskip-v4\",\n",
    "#         'stop_reward':      18.0,\n",
    "#         'run_name':         'pong',\n",
    "#         'replay_size':      100000,\n",
    "#         'replay_initial':   10000,\n",
    "#         'target_net_sync':  1000,\n",
    "#         'epsilon_frames':   10**5,\n",
    "#         'epsilon_start':    1.0,\n",
    "#         'epsilon_final':    0.02,\n",
    "#         'learning_rate':    0.0001,\n",
    "#         'gamma':            0.99,\n",
    "#         'batch_size':       32\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "USE_CUDA = torch.cuda.is_available() and USE_GPU\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: 21.00\n",
      "Action counts: Counter({3: 460, 1: 407, 2: 313, 5: 297, 0: 79, 4: 79})\n",
      "Total reward: 20.00\n",
      "Action counts: Counter({3: 542, 1: 425, 5: 317, 2: 218, 4: 161, 0: 67})\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ad109fdeba21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mFPS\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total reward: %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtotal_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Action counts:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# seed = 189762\n",
    "name = 'pong-1step-double-324267'\n",
    "# [324267, 250271, 189762, 542357, 519293, 516463, 353568, 110577, 953419, 405991]\n",
    "for seed in [324267, 250271, 189762, 542357, 519293, 516463, 353568, 110577, 953419, 405991]:\n",
    "    env = gym.make(params['env_name'])\n",
    "    env = ptan.common.wrappers.wrap_dqn(env)\n",
    "    #  Record video\n",
    "    env = gym.wrappers.Monitor(env, \"recording/\"+name+\"_\"+str(seed)+\"/\", video_callable=lambda episode_id: True,force=True)\n",
    "\n",
    "#     net = dqn_model.DQN(env.observation_space.shape, \n",
    "#                         env.action_space.n).to(device)\n",
    "    net = dqn_model.DQN(env.observation_space.shape, \n",
    "                        env.action_space.n).to(device)\n",
    "    MODEL_FILENAME = './models/pong-1step-double-dueling-324267.pt'\n",
    "#     MODEL_FILENAME = './models/pong/pong_basic/pong-basic_'+str(seed)+'.pt'\n",
    "    # MODEL_FILENAME = './models/pong/pong-nsteps_3/pong-nsteps_3_110577.pt'\n",
    "    # MODEL_FILENAME = './models/pong/pong-nsteps_4/pong-nsteps_4_110577.pt'\n",
    "\n",
    "    net.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "\n",
    "    VISUALIZE = True\n",
    "    FPS = 200\n",
    "\n",
    "    for plays in range(1):\n",
    "        state = env.reset()\n",
    "        total_reward = 0.0\n",
    "        action_counter = collections.Counter()\n",
    "\n",
    "        while True:\n",
    "            start_ts = time.time()\n",
    "            if VISUALIZE:\n",
    "                env.render()\n",
    "\n",
    "            state_v = torch.tensor(np.array(state, copy=False)).unsqueeze(dim=0)\n",
    "            q_vals = net(state_v.to(device)).data.cpu().numpy()[0]\n",
    "\n",
    "            action = np.argmax(q_vals)\n",
    "            action_counter[action] += 1\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "            if VISUALIZE:\n",
    "                delta = 1/FPS - (time.time() - start_ts)\n",
    "                if delta > 0:\n",
    "                    time.sleep(delta)\n",
    "        print(\"Total reward: %.2f\" % total_reward)\n",
    "        print(\"Action counts:\", action_counter)\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 189762\n",
    "# params = common.HYPERPARAMS['beamrider-v1']\n",
    "\n",
    "# name = 'beamrider_srg'\n",
    "# # [324267, 250271, 189762, 542357, 519293, 516463, 353568, 110577, 953419, 405991]\n",
    "# env = gym.make(params['env_name'])\n",
    "# env = ptan.common.wrappers.wrap_dqn(env)\n",
    "# #  Record video\n",
    "# env = gym.wrappers.Monitor(env, \"recording/\"+name+\"_\"+str(seed)+\"/\", video_callable=lambda episode_id: True,force=True)\n",
    "\n",
    "# net = dqn_model.DQN(env.observation_space.shape, \n",
    "#                     env.action_space.n).to(device)\n",
    "\n",
    "# MODEL_FILENAME = './models/beamrider-v0-basic-srg-953419.pt'\n",
    "# # MODEL_FILENAME = './models/pong/pong-nsteps_3/pong-nsteps_3_110577.pt'\n",
    "# # MODEL_FILENAME = './models/pong/pong-nsteps_4/pong-nsteps_4_110577.pt'\n",
    "\n",
    "# net.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "\n",
    "# VISUALIZE = True\n",
    "# FPS = 200\n",
    "\n",
    "# for plays in range(1):\n",
    "#     state = env.reset()\n",
    "#     total_reward = 0.0\n",
    "#     action_counter = collections.Counter()\n",
    "\n",
    "#     while True:\n",
    "#         start_ts = time.time()\n",
    "#         if VISUALIZE:\n",
    "#             env.render()\n",
    "\n",
    "#         state_v = torch.tensor(np.array(state, copy=False)).unsqueeze(dim=0)\n",
    "#         q_vals = net(state_v.to(device)).data.cpu().numpy()[0]\n",
    "\n",
    "#         action = np.argmax(q_vals)\n",
    "#         action_counter[action] += 1\n",
    "#         state, reward, done, _ = env.step(action)\n",
    "#         total_reward += reward\n",
    "#         if done:\n",
    "#             break\n",
    "#         if VISUALIZE:\n",
    "#             delta = 1/FPS - (time.time() - start_ts)\n",
    "#             if delta > 0:\n",
    "#                 time.sleep(delta)\n",
    "#     print(\"Total reward: %.2f\" % total_reward)\n",
    "#     print(\"Action counts:\", action_counter)\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
